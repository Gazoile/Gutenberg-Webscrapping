{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ddar7ZrhK1Kg"
   },
   "source": [
    "### PACKAGES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJxo1HY6mKyF",
    "outputId": "017d5bdc-abc2-4020-dd8f-cb7031ff0e48"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import chardet\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "from matplotlib.pyplot import plot\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de l'os de l'utilisateur du notebook\n",
    "platform.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgwSkCTku6tA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recup_info(row):\n",
    "    \n",
    "  # Instaciation d'un compteur à 0 pour tracker un éventuelle soucis\n",
    "  debug = 0\n",
    "    \n",
    "  #if \"Reminiscences of an Army nurse\" in row:\n",
    "  #debug  = 1\n",
    "\n",
    "  if debug == 1:\n",
    "    input(\"1 :\" + row)\n",
    "\n",
    "# traitement sur les caractères spéciaux présent dans les lignes\n",
    "  if row[0] == \"~\":\n",
    "    return None,None,None\n",
    "\n",
    "  if row == \"\\n\":\n",
    "    return None,None,None\n",
    "\n",
    "  if \"TITLE and AUTHOR\" in row:\n",
    "    return None,None,None\n",
    "\n",
    "\n",
    "  #\n",
    "  if row:\n",
    "    id = row.split()[-1]\n",
    "\n",
    "    row = row.replace(id,\"\")\n",
    "\n",
    "    row = row.replace(\"\\n\",\"\")\n",
    "\n",
    "# trouver ou sarette les espaces\n",
    "    # récupèrer l'index du 1er element qui n'est pas un espace en partant de la fin\n",
    "    # enlever les espaces en trop\n",
    "\n",
    "\n",
    "    if debug == 1:\n",
    "      input(\"2 :\" + row)\n",
    "\n",
    "    for i in range(len(row)):\n",
    "      if row[-1 - i] != \" \" and \" \":\n",
    "        row = row[:len(row) - i ]\n",
    "\n",
    "        break\n",
    "\n",
    "    if debug == 1:\n",
    "      input(\"3 :\" + row)\n",
    "\n",
    "\n",
    "\n",
    "  #j'instancie une variable vide pour y mettre la ligne du titre\n",
    "  titre_complet = \"\"\n",
    "  #tant que ', by' n'apparait pas dans la ligne c'est que le titre n'est pas encore complet.\n",
    "  while ', by' not in titre_complet:\n",
    "    # si il y a ', by' c'est que le titre est complet\n",
    "    if row:\n",
    "      # on stock le titre dans la variable\n",
    "      titre_complet = titre_complet + row.replace(\"\\n\",\"\")\n",
    "      # lecture de la prochaine ligne\n",
    "      row = f.readline()\n",
    "      if row == \"\\n\":\n",
    "        return None,None,None\n",
    "    # ??\n",
    "    else:\n",
    "      return None,None,None\n",
    "    # Equivalent à null mais avec une valeur ?\n",
    "\n",
    "    if debug == 1:\n",
    "      input(\"4 :\" + titre_complet)\n",
    "\n",
    "\n",
    "\n",
    "  # on nettoie la ligne contenant le titre de l'indentation et on split en\n",
    "  # deux avec le séparateur ', by' pour dissocier le titre de l'auteur\n",
    "  titre_complet = titre_complet.split(', by')\n",
    "\n",
    "  if debug == 1:\n",
    "      input(\"5 :\" + titre_complet[0])\n",
    "  #si titre est encore vid\n",
    "    # on lui assigne la premiere partie de la ligne actuelle\n",
    "  # on recupere la deuxieme partie de la ligne actuelle et on la split ? car\n",
    "  # cette deuxieme partie de la ligne contient plusieurs mots et ce qui nous intéresse\n",
    "  # c'est le dernier donc on split la deuxieme partie pour pouvoir slicer le dernier\n",
    "  # mot de celle-ci\n",
    "  #row1 = row[1].split()\n",
    "  # on passe à la ligne suivante\n",
    "  ##next_line = f.readline()\n",
    "  # tant qu'on a pas sauté de ligne\n",
    "  # donc que la ligne n'ai pas vide\n",
    "  while row != \"\\n\":\n",
    "    # et que si il y a du français dans cette ligne\n",
    "    if \"[Language: French]\" in row:\n",
    "\n",
    "\n",
    "      # alors on retourne le titre et l'ID de l'auteur\n",
    "      return titre_complet[0],titre_complet[1],id\n",
    "\n",
    "    # si il n'y a pas de français on passe à la ligne suivante\n",
    "    row = f.readline()\n",
    "  # ??\n",
    "  return None,None,None\n",
    "\n",
    "\n",
    "# Faire des reads line, à chaque résultat du readline\n",
    "# regarder si il y a le mot language et si oui si il y a le mot french\n",
    "# si c'est le cas on retourne nom du livre et numéro du livre jusqu'a ligne vide > return nom du bouqin , numéro ou rien\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gBlB9XKJDf1c",
    "outputId": "f6ee580a-e1f3-42c7-c621-469459972a96"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "titre = []\n",
    "auteur = []\n",
    "id = []\n",
    "\n",
    "\n",
    "# on instancie un dico vide\n",
    "info = {}\n",
    "# on instancie un compteur à 0\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "#chemin du fichier gutindex selon OS de l'utilisateur \n",
    "# Gutindex.all contenant titre auteur et id des textes\n",
    "if platform.system() == \"Windows\":\n",
    "    path = \"index\\\\GUTINDEX.ALL\"\n",
    "else:\n",
    "    path = \"index/GUTINDEX.ALL\"\n",
    "\n",
    "\n",
    "# ouverture de gutindex.all en mode read par défaut\n",
    "f = open(path)\n",
    "\n",
    "\n",
    "for l in tqdm(range(260)):\n",
    "  f.readline()\n",
    "# lecture et affichage des 260 premières lignes du fichier car les titres de livre\n",
    "# commence à partir de la ligne 260 donc on met notre curseur sur 260 pour que plus\n",
    "# bas dans notre code quand on utilise un readline il soit directement sur le\n",
    "# contenu qui nous intéresse\n",
    "\n",
    "\n",
    "# lecture de la premiere ligne\n",
    "row = f.readline()\n",
    "\n",
    "# tant qu'il y a des lignes dans notre document\n",
    "while row:\n",
    "\n",
    "  # incrémente le compteur de 1 à chaque nouvelle ligne traiter\n",
    "  i += 1\n",
    "\n",
    "  if \"Audio: \" not in row:\n",
    "\n",
    "\n",
    "    # on stock dans 2 variables distinctes les retours de notre fonction ()\n",
    "    title,auteur,id = recup_info(row)\n",
    "  #print(title,auteur,id)\n",
    "  # Si le titre qui nous est retourné par la fonction n'est pas nul\n",
    "    if title != None:\n",
    "    # on le stock comme clé dans le dico et on lui assigne en valeur l'id auteur\n",
    "      info[title] = id\n",
    "  # passage à la ligne suivante\n",
    "  row = f.readline()\n",
    "  #print(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #print(i)\n",
    "\n",
    "\n",
    "\n",
    "# Obtenir une liste de tout les titres et de tous les auteurs et de tous les id , sans doublons de titre et d'auteur  si il apparait deux fois je ne le veux qu'une seule fois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9njsJn8cWIwM",
    "outputId": "60bfd752-1530-4546-f0ad-3f13469a7e21"
   },
   "outputs": [],
   "source": [
    "#print(type(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZLQXZQmVRLr",
    "outputId": "3724d1ee-7ff9-4b3f-c251-dee75b764963"
   },
   "outputs": [],
   "source": [
    "#print(len(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDdt4zE0YtVC",
    "outputId": "e8916a2d-184a-400e-bc78-29909ea68987"
   },
   "outputs": [],
   "source": [
    "#for livre in info:\n",
    "\n",
    "#  print(livre,info[livre])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIgRzZpeFtss"
   },
   "outputs": [],
   "source": [
    "racine = \"http://aleph.gutenberg.org/\"\n",
    "\n",
    "#parcourir l'index du premier au dernier element puis ajouté à chaque fois le numéro et un slash à la racine.\n",
    "for titre in info:\n",
    "  id = info[titre]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2HxLpqaCplA"
   },
   "outputs": [],
   "source": [
    "TEXT_START_MARKERS = (\n",
    "    \"*END*THE SMALL PRINT\",\n",
    "    \"*** START OF THE PROJECT GUTENBERG\",\n",
    "    \"*** START OF THIS PROJECT GUTENBERG\",\n",
    "    \"This etext was prepared by\",\n",
    "    \"E-text prepared by\",\n",
    "    \"Produced by\",\n",
    "    \"Distributed Proofreading Team\",\n",
    "    \"Proofreading Team at http://www.pgdp.net\",\n",
    "    \"http://gallica.bnf.fr)\",\n",
    "    \"      http://archive.org/details/\",\n",
    "    \"http://www.pgdp.net\",\n",
    "    \"by The Internet Archive)\",\n",
    "    \"by The Internet Archive/Canadian Libraries\",\n",
    "    \"by The Internet Archive/American Libraries\",\n",
    "    \"public domain material from the Internet Archive\",\n",
    "    \"Internet Archive)\",\n",
    "    \"Internet Archive/Canadian Libraries\",\n",
    "    \"Internet Archive/American Libraries\",\n",
    "    \"material from the Google Print project\",\n",
    "    \"*END THE SMALL PRINT\",\n",
    "    \"***START OF THE PROJECT GUTENBERG\",\n",
    "    \"This etext was produced by\",\n",
    "    \"*** START OF THE COPYRIGHTED\",\n",
    "    \"The Project Gutenberg\",\n",
    "    \"http://gutenberg.spiegel.de/ erreichbar.\",\n",
    "    \"Project Runeberg publishes\",\n",
    "    \"Beginning of this Project Gutenberg\",\n",
    "    \"Project Gutenberg Online Distributed\",\n",
    "    \"Gutenberg Online Distributed\",\n",
    "    \"the Project Gutenberg Online Distributed\",\n",
    "    \"Project Gutenberg TEI\",\n",
    "    \"This eBook was prepared by\",\n",
    "    \"http://gutenberg2000.de erreichbar.\",\n",
    "    \"This Etext was prepared by\",\n",
    "    \"This Project Gutenberg Etext was prepared by\",\n",
    "    \"Gutenberg Distributed Proofreaders\",\n",
    "    \"Project Gutenberg Distributed Proofreaders\",\n",
    "    \"the Project Gutenberg Online Distributed Proofreading Team\",\n",
    "    \"**The Project Gutenberg\",\n",
    "    \"*SMALL PRINT!\",\n",
    "    \"More information about this book is at the top of this file.\",\n",
    "    \"tells you about restrictions in how the file may be used.\",\n",
    "    \"l'authorization à les utilizer pour preparer ce texte.\",\n",
    "    \"of the etext through OCR.\",\n",
    "    \"*****These eBooks Were Prepared By Thousands of Volunteers!*****\",\n",
    "    \"We need your donations more than ever!\",\n",
    "    \" *** START OF THIS PROJECT GUTENBERG\",\n",
    "    \"****     SMALL PRINT!\",\n",
    "    '[\"Small Print\" V.',\n",
    "    '      (http://www.ibiblio.org/gutenberg/',\n",
    "    'and the Project Gutenberg Online Distributed Proofreading Team',\n",
    "    'Mary Meehan, and the Project Gutenberg Online Distributed Proofreading',\n",
    "    '                this Project Gutenberg edition.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1PZpTo-NCz7X"
   },
   "outputs": [],
   "source": [
    "TEXT_END_MARKERS = (\n",
    "    \"*** END OF THE PROJECT GUTENBERG\",\n",
    "    \"*** END OF THIS PROJECT GUTENBERG\",\n",
    "    \"***END OF THE PROJECT GUTENBERG\",\n",
    "    \"End of the Project Gutenberg\",\n",
    "    \"End of The Project Gutenberg\",\n",
    "    \"Ende dieses Project Gutenberg\",\n",
    "    \"by Project Gutenberg\",\n",
    "    \"End of Project Gutenberg\",\n",
    "    \"End of this Project Gutenberg\",\n",
    "    \"Ende dieses Projekt Gutenberg\",\n",
    "    \"        ***END OF THE PROJECT GUTENBERG\",\n",
    "    \"*** END OF THE COPYRIGHTED\",\n",
    "    \"End of this is COPYRIGHTED\",\n",
    "    \"Ende dieses Etextes \",\n",
    "    \"Ende dieses Project Gutenber\",\n",
    "    \"Ende diese Project Gutenberg\",\n",
    "    \"**This is a COPYRIGHTED Project Gutenberg Etext, Details Above**\",\n",
    "    \"Fin de Project Gutenberg\",\n",
    "    \"The Project Gutenberg Etext of \",\n",
    "    \"Ce document fut presente en lecture\",\n",
    "    \"Ce document fut présenté en lecture\",\n",
    "    \"More information about this book is at the top of this file.\",\n",
    "    \"We need your donations more than ever!\",\n",
    "    \"END OF PROJECT GUTENBERG\",\n",
    "    \" End of the Project Gutenberg\",\n",
    "    \" *** END OF THIS PROJECT GUTENBERG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "np904KvwIoHr"
   },
   "outputs": [],
   "source": [
    "\n",
    "LEGALESE_START_MARKERS = (\"<<THIS ELECTRONIC VERSION OF\",)\n",
    "LEGALESE_END_MARKERS = (\"SERVICE THAT CHARGES FOR DOWNLOAD\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51NHnVqCI2VU"
   },
   "outputs": [],
   "source": [
    "def strip_headers(text):\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    sep = str(os.linesep)\n",
    "\n",
    "    out = []\n",
    "    i = 0\n",
    "    footer_found = False\n",
    "    ignore_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        reset = False\n",
    "\n",
    "        if i <= 600:\n",
    "            # Check if the header ends here\n",
    "            if any(line.startswith(token) for token in TEXT_START_MARKERS):\n",
    "                reset = True\n",
    "\n",
    "            # If it's the end of the header, delete the output produced so far.\n",
    "            # May be done several times, if multiple lines occur indicating the\n",
    "            # end of the header\n",
    "            if reset:\n",
    "                out = []\n",
    "                continue\n",
    "\n",
    "        if i >= 100:\n",
    "            # Check if the footer begins here\n",
    "            if any(line.startswith(token) for token in TEXT_END_MARKERS):\n",
    "                footer_found = True\n",
    "\n",
    "            # If it's the beginning of the footer, stop output\n",
    "            if footer_found:\n",
    "                break\n",
    "\n",
    "        if any(line.startswith(token) for token in LEGALESE_START_MARKERS):\n",
    "            ignore_section = True\n",
    "            continue\n",
    "        elif any(line.startswith(token) for token in LEGALESE_END_MARKERS):\n",
    "            ignore_section = False\n",
    "            continue\n",
    "\n",
    "        if not ignore_section:\n",
    "            out.append(line.rstrip(sep))\n",
    "            i += 1\n",
    "\n",
    "    return sep.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXcsVbMR7ciY",
    "outputId": "17706588-7179-497b-bbe4-fd37e1b8a640",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#incrémentation sur str pas possible\n",
    "i=0\n",
    "encoding_text = {}\n",
    "\n",
    "\n",
    " #chemin relatif selon os\n",
    "if platform.system() == \"Windows\":\n",
    "    path = \"text\\\\\"\n",
    "else:\n",
    "    path = \"text/\"\n",
    "\n",
    "# récupère la liste des fichiers présent dans le dossier text\n",
    "text_content = os.listdir(path)\n",
    "\n",
    " #condition pour ouverture du fichier que le .json soit présent dans le dossier text et ne soit pas vide\n",
    "if \"nos_encoding.json\" in text_content and os.path.getsize(path + \"nos_encoding.json\") > 0:\n",
    "    \n",
    "    # ouverture du fichier en mode lecture binaire\n",
    "    nos_encoding = open(path + \"nos_encoding.json\", mode=\"rb\")\n",
    "\n",
    "        \n",
    "    # lecture du fichier en mode binaire qui permet de récupérer les données précèdamments stockées\n",
    "    encoding_text = pickle.load(nos_encoding)\n",
    "    \n",
    "    # fermeture du fichier car on veut write dedans à la next step\n",
    "    nos_encoding.close()\n",
    "\n",
    "\n",
    "for titre in tqdm(info):\n",
    "  i+=1\n",
    "  id = info[titre]\n",
    "  #if id[-1] == \"C\":\n",
    "  #  id = id[:-1]\n",
    "\n",
    "  id = id.replace(\"C\",\"\")\n",
    "  id_f = \"\"\n",
    "  for e in id[:-1]:\n",
    "    id_f = id_f + e + \"/\"\n",
    "\n",
    "    #print(id_f)\n",
    "  gut = id_f + id\n",
    "\n",
    "    \n",
    "\n",
    "  if id + \".txt\" in text_content and os.path.getsize(path + f\"{id}.txt\") > 0:\n",
    "      continue \n",
    "\n",
    "\n",
    "    \n",
    "  url_fi = racine + gut\n",
    "  corpus = requests.get(url_fi)\n",
    "  resultat = \"\"\n",
    "  index = corpus.text.find(\".txt\")\n",
    "  if index != -1:\n",
    "    for e in corpus.text[index+3:0:-1]:\n",
    "      resultat = e + resultat\n",
    "      if e == \"-\":\n",
    "        break\n",
    "    url_fi = url_fi + \"/\" + id + resultat\n",
    "    corpus.close()  \n",
    "    corpus = requests.get(url_fi)\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "    \n",
    "    result = chardet.detect(corpus.content)\n",
    "\n",
    "      \n",
    "    corpus.encoding=result['encoding']\n",
    "    #print(corpus.encoding)\n",
    "    corpus1 = corpus.text \n",
    "    corpus1 = strip_headers(corpus1)\n",
    "    encoding_text[id] = result['encoding']\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "      \n",
    "        \n",
    "   \n",
    "    \n",
    "    \n",
    "#recup la list des fichiers que j'ai déjà\n",
    "      \n",
    "        # pour chacun des ficheirs que je veux récup sur internet voir si je l'ai déjà si c le cas ksip\n",
    "    try :\n",
    "        #z = open(f\"/content/drive/MyDrive/Test/{id}.txt\",mode=\"w\",encoding=\"utf-8\")\n",
    "        # ouverture du fichier d'un texte \"nom d'un id\"\n",
    "        z = open(path + f\"{id}.txt\", mode=\"w\",encoding=result['encoding'])\n",
    "\n",
    "        z.write(corpus1)\n",
    "        z.close()\n",
    "        \n",
    "      \n",
    "        \n",
    "    except :\n",
    "        print(id)\n",
    "        print(result)\n",
    "        z = open(path + f\"{id}.txt\", mode=\"w\",encoding='utf-8')\n",
    "\n",
    "          \n",
    "        corpus.encoding='utf-8'\n",
    "        #print(corpus.encoding)\n",
    "        corpus1 = corpus.text \n",
    "        corpus1 = strip_headers(corpus1)\n",
    "\n",
    "        z.write(corpus1)\n",
    "        z.close()\n",
    "\n",
    "        encoding_text[id] = 'utf-8'\n",
    "\n",
    "    corpus.close()\n",
    "\n",
    "    # ouvrir un fichier quand il n'existe pas c'est le créer\n",
    "    nos_encoding = open(path + \"nos_encoding.json\", mode=\"wb\")\n",
    "    \n",
    "    pickle.dump(encoding_text, nos_encoding)\n",
    "      \n",
    "    nos_encoding.close()\n",
    "        \n",
    "\n",
    "        \n",
    "    #print(id)\n",
    "    #print(url_fi)\n",
    "    #if i == 3:\n",
    "      #break\n",
    "  #if id[-1] == \"C\":\n",
    "  #  id = id[:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# la référence au fichier n'est pas libéré et donc la fonction write est toujours en attente d'ajout au buffer\n",
    "#nos_encoding.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nos_encoding = open(path + \"nos_encoding.json\", mode=\"rb\")\n",
    "dicz = pickle.load(nos_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicz[\"56473\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qt1psIe3N3L6"
   },
   "outputs": [],
   "source": [
    "corpus.text.find(\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaubCxRVtdTG"
   },
   "outputs": [],
   "source": [
    "corpus.text[355:361]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZhHGOWgn1BMI"
   },
   "outputs": [],
   "source": [
    "resultat = \"\"\n",
    "for e in corpus.text[361:0:-1]:\n",
    "    resultat = e + resultat\n",
    "    if e == \"-\":\n",
    "        break\n",
    "\n",
    "print(resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKN4HmaTOHJ0"
   },
   "outputs": [],
   "source": [
    "id0 = id + corpus.text[355:361]\n",
    "\n",
    "\n",
    "#remonter en arriere jusqu'au tiret\n",
    "#tant qu'on ne trouve pas de tiret continuer\n",
    "#print(id0)\n",
    "\n",
    "#url_fi = url_fi + \"/\" + id0\n",
    "print(url_fi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozWRlah-QRTv"
   },
   "outputs": [],
   "source": [
    "livre = requests.get(url_fi).text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wp8UYX3q6E_Y"
   },
   "outputs": [],
   "source": [
    "print(livre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyFxMidn2oLU"
   },
   "outputs": [],
   "source": [
    "#and eBook #12714 is in this subdirectory:\n",
    "        #1/2/7/1/12714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDte1J1Q2oCa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
